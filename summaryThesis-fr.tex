
\documentclass[a4paper,11pt,twoside]{report}

\usepackage[french]{babel}
\selectlanguage{french}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{fancyvrb}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
\bibliographystyle{unsrt}
\usepackage{url}
\usepackage{listings}
\usepackage{tabularx}
\usepackage{pdflscape}
\usepackage{subfigure}
\usepackage{wrapfig,lipsum,booktabs}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{gensymb}
\usepackage{pifont}

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\newcommand{\trans}[1]{\noindent\textcolor{red}{{\bf \{TRANS}: #1{\bf \}}}}

\begin{document}

\chapter*{R\'{e}sum\'{e}}
Au cours de ces dernières années, le domaine de l'Open Data a reçu une attention croissante de la part des administrations publiques qui veulent tirer avantage de la publication de données ouvertes sur le Web. Les bénéfices supposés de cette ouverture pour les citoyens font référence à une meilleure transparence dans les prises de décisions publiques, à une meilleure gouvernance ou encore au développement d'un éco-système numérique qui tirerait un profit économique des applications analysant ces données. Cependant, la réalité montre que la simple ouverture et la publication de données par les administrations ne sont pas suffisantes au regard des défis liés à la variété des formats (XML, CSV, Excel, PDF, Shape), des méthodes d'accès (API, base de données) et à l'absence de nomenclature qui permettrait une meilleure réutilisation et interconnexion avec d'autres jeux de données. Dans cette thèse, nous explorons comment l'utilisation des standards et des technologies du web sémantique peut aider à résoudre les problèmes causés par l'hétérogénéité et la diversité des formats de données et des structures de représentations dans le domaine géographique.

Cette thèse applique les principes des « données liées » dans le domaine de l'information géographique, un domaine clef pour les administrations publiques qui couvrent, par définition, un territoire. En particulier, nous traitons de trois aspects essentiels dans le workflow de traitement et de publication de données géo-spatiales et de leur consommation (visualisation), avec des scénarios d'utilisation issus de l’Institut Nationale de l’Information Géographique et Forestière (IGN) : (1) Comment représenter efficacement et stocker des données géospatiales sur le Web pour assurer des applications interopérables ? (2) Quelles sont les meilleures options pour un utilisateur pour interagir avec des données sémantiques interconnectées ? (3) Quels mécanismes peuvent être mis en place pour aider à la préservation des données structurées de haute qualité sur le Web?

Nos contributions sont structurées en trois grandes parties correspondantes aux problématiques susmentionnées, avec des applications spécifiques dans le domaine géographique. Nous proposons et développons trois vocabulaires pour représenter des systèmes de coordonnées de référence (CRS), des entités topographiques et la géométrie associée à ces entités. Ces ontologies étendent d'autres vocabulaires existants et ajoutent deux avantages supplémentaires : l’utilisation explicite de CRS identifiés par des URIs pour représenter la géométrie, et la capacité de décrire des géométries structurées en RDF. Nous avons ainsi publié la base de données GEOFLA, en contribuant et utilisant la plate-forme Datalift, un outil permettant de convertir et publier des données brutes en données liées. Nous avons également évalué de manière systématique la performance des points d'accès SPARQL pour traiter des requêtes spatiales.

Concernant la « consommation » de données RDF, après avoir examiné les différentes catégories des outils de visualisation (génériques et spécifiques à des jeux de données), nous proposons un vocabulaire pour décrire les applications de visualisation (DVIA). En outre, nous formalisons et mettons en œuvre un workflow pour visualiser des données sémantiques interconnectées à travers l'outil LDVizWiz, un assistant de visualisation générique de données liées sur le Web. 

La dernière partie de la thèse décrit des contributions au catalogue des vocabulaires liées (LOV) ainsi qu'une proposition originale pour utiliser LOV avec une méthodologie de création d'ontologie telle que NeOn dans le but d'améliorer la réutilisation des vocabulaires. Nous proposons une heuristique pour aligner les vocabulaires et un classement de ces derniers en fonction de métriques liées au contenu de l'information des termes définis dans les vocabulaires. Enfin, la thèse apporte des réponses sur la façon de vérifier la compatibilité des licences entre les vocabulaires et les jeux de données dans le workflow de publication. Tout au long de la thèse, nous démontrons les avantages de l'utilisation des technologies sémantiques et des standards du W3C pour mieux découvrir, interconnecter et visualiser les données géospatiales gouvernementales pour leur publication sur le Web.

Our main concern is to tackle the problems within the workflow of publication in two directions, more likely to happen at the beginning and the end: 
\begin{itemize}
\item (i) Geographic Information on the Web of Data: as an application of the life-cycle of publishing geodata.
\item (ii) Visualization tools for building innovative applications consuming structured data: as for leveraging the process of creating applications on-top of semantic data to highlight some relevant knowledge to the users.

\end{itemize}

Notre but principla est de résoudre les problèmes liés à la chaîne de publication dans deux directions, plus susceptible de se produire en début et en fin de chaîne:
\begin{itemize}
\item (i) l'information géographique sur le Web de données: comme une application du cycle de vie de publication des données geo-spatiales.
\item (ii) des outils de visualisation pour créer des applications innovantes utilisant les données structurées: comme pour tirer parti du processus de création des applications au-dessus des données sémantiques afin de mettre en excergue  des connaissances pertinentes pour les utilisateurs.
\end{itemize}

\chapter*{Questions de recherche}

Dans cette thèse, nous proposons des solutions dans les défis liés à la publication des données géographique sur le Web des données, qui sont les suivantes: 

\begin{enumerate}

\item \textit{Vocabulaires:} Comment modéliser l'information géographique sur le Web? Comment évaluer les ontologies du domaine géographique? Comment sérialiser les géométries complexes dans un environnement comme le Web? 
\item \textit{Languages de requêtes:} Comment pouvons-nous écrire des requêtes efficaces qui ciblent les données géospatiales sur le Web? Comment pouvons-nous stocker et indexer les géodonnées en RDF?

\item \textit{Données:} Comment pouvons-nous extraire et convertir les géodonnées pour publication sur le Web? Quelles sont les bonnes pratiques pour représenter des géométries complexes sur le Web? Comment pouvons-nous intégrer pleinement la compatibilité des systèmes de coordonnées  sur des jeux de données?

\item \textit{Publication:} Comment pouvons-nous développer des environnements qui passent à l'échelle pour couvrir le chaîne de publication des géodonnées? Quels sont les triples stores appropriées pour le stockage des géodonnées? Quelles sont les métriques à utiliser pour l'interconnexion de différentes ressources de géodonnées sur le Web? 

\item \textit{Applications et interfaces utilisateurs:} 
Comment pouvons-nous générer des visualisations de données géospatiales liées entre elles? Quels sont les API de haut niveau appropriées qui facilitent le développement d'interfaces utilisateur pour les données géospatiales? Pouvons-nous réutiliser les outils de cartographie existants tels que Google Maps, Bing Maps ou OpenSteetMap?

\end{enumerate}


Dans cette thèse, nous abordons les enjeux de publication des données du point de vue tant par les éditeurs que des utilisateurs. Les éditeurs et les utilisateurs ont besoin de solutions pragmatiques qui les aident à choisir un vocabulaire, trouver un outil pour convertir des fichiers shape  ShapeFiles selon des vocabulaires existants, puis transformer en RDF et publier les données suivant des bonnes pratiques.

 
Après la publication du jeux de données sur le Web, les éditeurs et les utilisateurs doivent comprendre ces données pendant que les développeurs doivent pouvoir créer des applications. Le Web commence à contenir de plsu en plus de données structurées, qui ne sont pas toujours exploitées par les utilisateurs finaux, à cause de la complexité dans l'usage du modèle RDF et de son langage de requête, le SPARQL. Ainsi, il est important de créer des visualisations pour explorer, analyser et montrer les bénéfices du Linked Data aux non-experts. Dans ce processus, il existe des questions de recherches à résoudre telles que:

\begin{itemize}
\item Comment trouver visualisations adaptées selon les jeux de données tout en masquant la complexité du language de requêtes SPARQL?

 \item  Quelles sont les propriétés importantes pour visualiser les ressources du Web, en fonction du domaine et des attentes des utilisateurs?
 
 \item  Comment combler le fossé entre les outils traditionnels existants de visualisation de l'information, la plupart du temps aux formats CSV/XLS, JSON ou formats propriétaires pour intégrer facilement le modèle de données RDF en entrée?
 
 \item Comment développer des applications interopérables sur les catalogues de données gouvernementaux en  Open Data? Comment réutiliser les applications existantes?
 
\end{itemize}
 
 
Tout en essayant de répondre aux défis ci-dessus mentionnés, nous exposons  l'état de l'art et approches existantes dans le domaine des visualisations de données liées.

\section*{Contributions}
\label{sec:contributions}


Les contributions de cette thèse sont organisée en trois parties principales: la modélisation et la publication des données géospatiales, la visualisation de données et des applications sur le Web et la contribution dans les standards.

\subsection*{Modélisation et Publication des données géospatiales}

La géolocalisation est cruciale pour de nombreuses applications tant pour agents humains que les logiciels. De plus en plus des masses de données sont ouvertes et interconnectées sur le Web. Une modélisation des données géographiques de manière efficace en réutilisant autant que possible des ontologies ou des vocabulaires existants qui décrivent à la fois les fonctionnalités géospatiales et leurs formes. Dans la première partie de notre travail, nous examinons différentes approches de modélisation utilisées dans les systèmes d'information géographique (SIG) et la communauté des données ouvertes (LOD). Notre objectif est de contribuer aux efforts réels dans la représentation des objets géographiques avec des attributs tels que l'emplacement, les points d'intérêt (POI), et les adresses sur le Web de données. Nous nous concentrons sur le territoire français et nous fournissons des exemples de vocabulaires représentatifs qui peuvent être utilisés pour décrire les objets géographiques. Nous proposons quelques alignements entre différents vocabulaires (DBpedia, schema.org, LinkedGeoData, Foursquare, etc.) afin de permettre l'interopérabilité tout en interconnectant les géodonnées en France avec d'autres jeux de données.
 
Concernant cet aspect de notre recherche, nos contributions sont les suivantes:  

 \begin{enumerate}
 
  \item  Nous avons proposé et développé une ontologie décrivant les caractéristiques et les points d'intérêt pour le territoire français, en réutilisant une taxonomie existante (GeOnto) en l'alignant sur d'autres vocabulaires connexes dans le domaine de la géolocalisation.
 
  \item  Nous avons étudié comment étendre les vocabulaires existants dans le domaine géographique afin de prendre en compte une modélisation efficace des géométries complexes. Ce faisant, nous abordons les questions de représentation de géométrie complexe dans le Web de données, décrivant l'état de mise en oeuvre des fonctions géospatiales dans triples stores et une comparaison avec la nouvelle norme GeoSPARQL. Nous faisons enfin quelques recommandations et plaidons pour la réutilisation des vocabulaires plus structurées pour la publication d'entités topographiques pour mieux répondre aux exigences des données issues de IGN-France.
 
 \item Nous avons fait une étude comparative des triples stores, comparant leur capacité de stockage des informations spatiales et leur implémentation des fonctions topologiques ra rapport à celles déjà existantes dans les normes de l'Open Geospatial Consortium (OGC)\footnote{\url{http://www.opengeospatial.org/}}.

 \item  Nous avons conçu et développé des vocabulaires pour décrire les géométries complexes avec différents systèmes de coordonnées, avec application directe aux unités administratives françaises.
 

 \item Nous avons interconnecté des géodonnées du contexte français avec des jeux de données géospatiales existantes sur le Web, tels que LinkedGeodata, GADM, NUTS et Geonames.
 
 \item Nous avons contribué à la création du ``nuage données'' ( LOD Cloud) représentant la publication de 8 jeux de données, soit 340 millions de triplets couvrant le territoire français.
 

\end{enumerate}
 
Consommer des données sur le Web grâce à des visualisations comporte autant de défis que les applications doivent de conformer à la structure du graphe RDF, la sémantique sous-jacente du jeu de données et de l'interaction homme-machine pour comprendre facilement de quoi traitent ces données. Dans la section suivante, nous présentons nos contributions sur la visualisation.

\subsection*{Outils de visualisation des données gouvernementales liées} 
\label{visu}

Nous étudions d'abord quelques applications innovantes qui ont été développées sur des jeux de données publiées en Open Data par les gouvernements (Royaume-Uni, USA, France) et des administrations locales. Nous avons ensuite dérivé et proposé 8 cas d'utilisation (scénarios) qui peuvent être développées pour consommer des données provenant des différents fournisseurs principaux en France: INSEE, DILA, IGN, FING, etc. Nous mentionnons que les cas d'utilisation les plus intéressants sont ceux qui montrent la valeur ajoutée des jeux de données interconnectées. Ces scénarios développés et déployés, peuvent être utiles pour montrer les avantages de données liées dans une variété de domaines tels que l'éducation, le tourisme, le patrimoine culturel, les administrations civiles, les tribunaux, la médecine, etc.


En ce qui concerne les outils utilisés pour la visualisation, nous avons identifié et classer en deux catégories, en fournissant pour chacun d'eux des exemples pertinents: (i) - des outils qui fonctionnent sur des données RDF, et (ii) des outils qui fonctionnent sur d'autres formats structurés. Nous proposons donc des critères de base pour évaluer un outil de visualisation de donnée en général, avec des poids attachés à chaque critère.

Nos contributions sur la visualisation sont les suivantes: 

\begin{enumerate}

\item 
Nous avons construit une application des élections présidentielles du premier tour français en 2012 en utilisant les données de \url{http://data.gouv.fr} et d'autres institutions publiques. L'application disponible à \url{http://www.eurecom.fr/~atemezin/DemoElection/} a été construit avec l'outil Exhibit. Il vise à mettre en valeur l'intégration des jeux de données hétérogènes: les résultats politiques en CSV, le taux de chômage, les données des candidats, les informations des départements de France provenant des données DBpedia. L'utilisateur peut filtrer par image du candidat, le taux de chômage et par département pour voir les scores, avec des informations plus enrichies sur le département.
 
\item 
Nous avons mis en place un outil générique pour explorer les géodonnées sur une carte, en fonction de la détection automatique des données via de requêtes SPARQL dans le nuage LOD contenant des jeux de données géospatiales.


\item 
Nous avons développé une application consommatrice de données géospatiales et statistiques combinant plusieurs jeux de données dans l'éducation de provenant du portail \url{http://data.gouv.fr} .

\item 
Nous avons développé une application sur les événements dans une conférence avec leurs médias supports réconciliés provenant de nombreuses plates-formes sociales (Instagram, Twitter, etc.).

\item 
Nous avons implémenté un vocabulaire pour structurer les applications sur le Web de données. Le vocabulaire peut être utilisé pour découvrir des outils visuels ou graphiques utilisés pour créer des applications.

\item 
Nous avons mplémenté un plugin générique pour annoter des applications déve- loppées pour des hack-athon pouvant être inclus dans une page web, permettant la génération de contenu structuré de pages Web en utilisant le vocabulaire développé.

\item 
Nous avons mis en place un assistant qui analyse un jeu de données RDF et  recommande une visualisation basée sur des catégories prédéfinies, en utilisant des requêtes SPARQL génériques pour faciliter l'exploration des jeux de données publiés sur le LOD.


\end{enumerate}



\subsection*{Contributions aux standards}
\label{sec:contrib-standard}
We contributed to the W3C Government Linked Data Working Group (GLD WG)\footnote{http://www.w3.org/2011/gld/} activity from July 2011 until December 2013.  The objective of the Working Group was to \textit{``provide standards and other information which help governments around the world publish their data as effective and usable Linked Data using Semantic Web technologies''}.

Nous avons contribué aux activités du groupe du W3C sur les données gouvernementales liées de travail (GLD WG)\footnote{http://www.w3.org/2011/gld/} de juillet 2011 jusqu'à décembre 2013. L'objectif du Groupe de travail était de «fournir des normes et d'autres informations qui aident les gouvernements à travers le monde dans la publication de leurs données aussi efficace qu'utilisable à l'aide des technologies du Web sémantique ".

Nous avons contribué à trois groupes de travail, avec en particulier dans deux documents:
\begin{enumerate}
\item Un glossaire\footnote{\url{http://www.w3.org/TR/ld-glossary/}} pour la description des termes utilisés dans le domaine du Linked data pour les potentiels producteurs et consommateurs de données gouvernementales sur le Web
\item Un document sur les bonnes pratiques de publication des données gouvernementales sur le Web\footnote{\url{http://www.w3.org/TR/ld-bp/}}

\end{enumerate}


En ce qui concerne l'utilisation de vocabulaires standards, nous avons contribué à: 
\begin{itemize}

\item  
Proposer une méthode pour harmoniser les préfixes sur le Web de données avec deux services: Linked Open vocabulaires (LOV)\footnote{\url{http://lov.okfn.org/dataset/lov/}} prefix.cc\footnote{\url{http://prefix.cc}}. le premier service est actuellement un catalogue à jour des vocabulaires utilisés sur le Web, tandis que le dernier est un service pour les développeurs pour choisir, valider et chercher des préfixes pour leurs ressources ou ontologies. L'approche proposée peut être étendue à tout le catalogue du vocabulaire tant que les vocabulaires remplissent les conditions pour être insérées dans le catalogue LOV.


\item  
Concevoir et mettre en œuvre une nouvelle méthode de classement des vocabulaires sur la base des métriques du contenu de l'information et de l'information partitionnée.

\item 
Nous avons développé un outil qui détermine en temps réel si les différentes licences présentes dans un jeu de données et les vocabulaires associés sont soit compatible ou non.

\end{itemize}









\chapter*{Plan de la Thèse} 
\label{sec:thesis-structure}

Dans la première partie de cette thèse , nous nous concentrons sur l'étude des différents modèles et vocabulaires pour représenter la géographie et de la géométrie . Nous étudions les points d'accès aux données et décrivons les problèmes particuliers tels que les systèmes de coordonnées, et mettons en évidence nos contributions dans ce dommaine: création de nouveaux vocabulaires réutilisant les vocabulaires existants, implémentation d'un convertisseur en ligne entre des différents systèmes de coordonées, etc. Nous décrivons également comment des jeux de données géographiques peuvent ensuite être convertis en RDF en utilisant le processu d'élévation des données du projet Datalift afin de leur publication sur le Web. Nous montrons ensuite comment ces jeux de données peuvent être alignées entre elles et concluons par une analyse approfondie de ces alignements dans le cas des jeux de données de cartographie française fournis par l'Institut Géographique et Forestière (IGN -France ) . 

Plus précisement:

 
  \textbf{Le Chaptitre 1} 
  décrit les limites actuelles de représentation des géodonnées sur le Web et notre contribution sur les différents vocabulaires pour représenter les géométries, les systèmes de coordonnées de référence et les ressources topographiques. Nous proposons également des bonnes pratiques pour la publication des données géospatiales sur le Web.
 \textbf{Le Chapitre 2} 
 met l'accent sur les outils de publication et des requêtes d'interrogation des géodonnées, leurs différences et leurs applications. Nous décrivons la plate-forme Datalift, une plate-forme ouverte servant de catalyseur des sources de données brutes vers des données sémantiques et interconnectés. Après avoir comparé Datalift avec Geoknow, nous l'appliquons dans le processus de publication d'unités administratives et le Gazetteer français. Nous présentons ensuite l'état du nuage français LOD (FrLOD) des données liées et des exemples de requêtes sur des géométries structurées publiées dans le point d'accès \url{http://data.ign.fr}.
 
 
 Dans la deuxième partie de la thèse, nous couvrons trois principales questions relatives à la façon de présenter les données en RDF aux utilisateurs finaux. Tout d'abord, nous présentons l'état de l'art des outils et des solutions pour la représentation visuelle et l'exploration des données en RDF (Visualbox, LODSpeaKr, Map4RDF, le modèle ``Linked Data Visualization'', etc.). Ensuite, nous présentons notre contribution: un assistant pour faciliter les visualisations automatique des points d'accès aux données sur le Web, y compris le vocabulaire spécifiant les visualisations et le prototype implémenté. Par la suite, nous présentons deux applications dans les domaines événementiel et statistique pour mettre en exergue de manière innovante la réutilisation des jeux de données liés. Enfin, nous implémentons un algorithme permettant de révéler les propriétés les plus ``importantes'' des entités des ressources pour leur visualisation en partant de la Base de Connaissance de Google (GKP) ainsi qu'une évaluation faite sur les préférences des utilisateurs. 
 
 Cette partie est divisée en deux chapitres:
 
  \textbf{Le Chapitre 3} 
  fournit une revue de littérature sur des outils de visualisation et les applications, avec leurs limites. Nous décrivons également l'état de l'art des applications sur le Web et proposons une classification des «Applications de données liées".
  

  Dans le \textbf{Chapitre 4}, nous présentons notre contribution sur de nouvelles approches pour générer des visualisations et des applications. Nous proposons tout d'abord une nouvelle approche pour les visualisations basées sur des catégories. Nous montrons ensuite une application dans le domaine géographique. Deux applications liées aux événements et aux statistiques sont également décrits. Enfin, nous proposons la façon d'améliorer la découverte d'applications dans les événements Open Data grâce à un modèle et un plugin universel pour annoter des pages Web en RDFa.


Dans la dernière partie de la thèse dans le \textbf{Chapitre 5}, nous décrivons diverses contributions aux vocabulaires ouverts liés (description du catalogue, les publications des vocabulaires, des API et des points d'accès): l'harmonisation des préfixes des vocabulaire, les métriques pour classer les vocabulaire  en utilisant le contenu de l'information. 

Dans le \textbf{Chapitre 6}, nous présentons quelques idées sur la vérification de compatibilité des licence entre les vocabulaires et les jeux de données en utilisant la logique déontique en créant un outil en ligne pour la détection automatique des licences sur es données du Web.

Dans le \textbf{Chapitre 7}, nous concluons en mettant en évidence certaines limites et perspectives pour de nouvelles directions de recherche.





\chapter*{Partie I: Intégration des données geo-spatiales sur le Web}

Cette partie est divisée en deux chapitres et consacrée à l'état de l'art sur les formats et les differents vocabulaires utilises dans la littérature pour  

\section*{Chapitre I}


Dans ce chapitre, nous faisons une revue de la litterature des formats et des différents vocabulaires utilisés pour modéliser des données géospatiales sur le Web, en distinguant deux types de géoréférencement: direct et indirect. Ensuite, nous identifions certaines limitations liés à l'absence d'une référence explicite du Systeme de coordonné géographique (SCG) dans les jeux de données actuellement publiés sur le Web. Nous proposons ensuite un service REST pour la conversion entre différents SCG pour aider les éditeurs à être capable de gérer différentes projections dans les jeux données. En outre, nous proposons et implémentons trois vocabulaires pour les géométries, les SCG et les entités topographiques qui sont en ligne aux adresses respectives à \url{http://data.ign.fr/def/geometrie}, \url{http://data.ign.fr/def/ignf} et \url{http://data.ign.fr/def/topo}. Les vocabulaires étendent ceux existants et intègrent deux avantages supplémentaires: un usage explicite de SCG identifiés par des URIs pour la géométrie et la capacité à décrire des géométries structurées en RDF. Certains de nos résultats et la description du modèle sont en cours de discussion pour la standardisation au W3C, comme par exemple étendre le standard  GeoSPARQL pour intégrer de manière plus explicite les coordonnées géographiques. 



\section*{Chapitre II}


Dans ce chapitre, nous présentons une étude des outils d'extraction et de conversion de données géospatiales en RDF. Ensuite, nous décrivons \texttt{GeomRDF}, un outil développé au sein du projet Datalift qui va au-delà de l'état de l'art en fournissant des géométries structurées et conformes au standard GeoSPARQL. En outre, nous présentons les limites des modèles de données existants en suggérant des recommandations aux éditeurs de géodonnées sur les aspects de stockage de gros volumes de donnés. De même, une description détaillée de l'outil Datalift utilisé pour publier des données sur le Web est fournie, avec une attention particulière sur notre contribution à la construction du nuage des données du Linked Open Data sur des données du territoire français avec des jeux de données en 4-5 étoiles selon les principes de données liées. Enfin, nous montrons quelques cas d'utilisation du monde réel des requêtes SPARQL faisant usage tour à tour de la géométrie structurée ou des fonctions géospatiales intégrées dans le triple store. Selon les besoins des utilisateurs et les jeux de données sous-jacentes, l'utilisateur peut choisir entre la simplicité du languqge de requête SPARQL, avec des limitations au niveau du triple store (par exemple, lors de l'usage des fonctions géospatiales intégrées), ou l'expressivité du du vocabulaire que nous proposons (\texttt{geom}), comme critère dans le choix du triple store et du stockage des données géospatiales.


\chapter*{Partie II: Visualisation des graphes de données sur le Web}

\section*{Chapitre III}

In this chapter, we have described different tools used for visualizing data, structured and graph data. We have also discussed different types of applications currently built on top of government open data initiatives. The goal of this survey is to propose some new approaches of generating and discovering visualizations and applications on the Web of Data. We designed and implemented DVIA, a vocabulary that aims to model applications for more interoperability and discovery of applications and tool visualizations on the Web.

\section*{Chapitre IV}

In this chapter we have presented  an approach for creating visualizations on top of Linked Data based on Semantic Web technologies. We first defined seven categories of objects worth viewing in a dataset, and we propose to associate them with commonly used and domain vocabularies. We then present a description of the main components of a Linked Data Visualization Wizard. We describe a lightweight implementation in JavaScript as a \textit{proof-of-concept} of our proposal, with the benefits to be usable on-line or being extensible. We advocate that such a tool can be easily integrated  in any workflow/framework for publishing and linking data on the Web, such as Datalift or the GeoKnow Stack. Besides, we have performed experiments on GKP to look for important properties in entities, and evaluated against users' preferences. Then we presented two applications in the domain of statistics and events, consuming different datasets in RDF on real-world scenario. We discussed on how to improve applications developed for contests, by proposing a vocabulary and a tool for populating the model by using a universal plugin. Some past events have been already semi-automatically curated using both the vocabulary and the plugin.



\chapter*{Partie III: Contribution au catalogue des vocabulaires liés}

\section*{Chapitre V}

We have presented in this chapter our contribution to Linked Open Vocabularies, as part of implementations of the benefits of using LOV in ontology engineering (case of NeOn methodology), prefixes harmonization and alignment of vocabularies published on the Web, or on ranking vocabularies using the principles of Information Content. By applying this latter to Linked Open Vocabularies, we tried to use features that we consider ``relevant'' to be taken into account when comparing vocabularies (e.g: datasets reused, external vocabularies). We compare with other rankings that are mostly based on the ``popularity'' of vocabularies. This work can path the way for assessing vocabularies with applications in a more systemic approach for recommending classes/properties in ontology management, or in visualization applications to propose the most \textit{``oh yeah?''} suitable property to be visualized for RDF entities when there is large a large number of properties.

\section*{Chapitre VI}

In this chapter, we have presented an online tool to check the compatibility between datasets and vocabularies based on the RDF-defeasible of SPINdle. We have introduced the LIVE framework for licenses compatibility. The goal of the framework is to verify the compatibility of the licenses associated to the vocabularies exploited to create a RDF dataset and the license associated to the dataset itself. Several points have to be taken into account for future work. 
%More precisely, in the present paper we consider vocabularies as data but this is not the only possible interpretation. For instance, we may see vocabularies as a kind of compiler, such that, after the creation of the dataset then the external vocabularies are no more used. In this case, what is a suitable way of defining a compatibility verification? We will investigate this issue as well as we will evaluate the usability of the online LIVE tool to subsequently improve the user interface

%our contributions on achieving some of the guidelines of the best practices of publishing Linked Data, by presenting the LOV catalogue, the harmonization of LOV with other catalogues, the importance of using semantics to rank vocabularies. Besides, we have presented Data2Ontology, a module aim at helping the reuse of existing vocabularies during the publication of data in Datalift. We finished by presenting \texttt{LIVE},

\chapter*{ Conclusion et Perspectives}
\label{ch:conc}


Cette thèse est consacrée aux défis de la publication des données géospatiales sur le Web et une approche plus générique de visualiser les données liées pour les utilisateurs. La première considère la diversité des différents formats utilisés pour publier les données géospatiales propriétaires, les différentes projections (ou systèmes de coordonnées de référence) et la représentation des géométries complexes. Cette dernière approche est différente de l'état-de-l'art dans les visualisations où la complexité du langage SPARQL et RDF est pas suffisamment cachée des utilisateurs. Une analyse approfondie de la littérature a révélé certaines limites dans la publication des données géospatiales et des outils de visualisation, à savoir:

\begin{itemize}
\item  
Une présence limitée des géométries complexes représentées de manière structurée, au lieu de littéraux.

\item 
L'absence d'une référence explicite aux SCG dans les données au géoréférencement direct sur le Web.

\item 
Absence d'outil de visualisation destiné aux utilisateurs permettant de comprendre facilement l'essence des données sous-jacentes publiées en LOD.

\item 
Beaucoup de silos de données pour les applications publiées sur le Web, perdues dans de nombreuses pages HTML.

\item 
Peu d'outils qui fournissent un environnement intégré pour la publication des données brutes en données liées, partant la modélisation de données jusqu'à l'étape finale de stockage du jeu de données dans un store RDF. 

\item La difficulté pour les éditeurs de données de comprendre et de vérifier la compatibilité des licences entre les vocabulaires et les jeux de données qu'ils réutilisent venant du LOD.

  
\end{itemize}

In this thesis, we have provided different vocabularies that all together support the publication of geodata integrating almost all the CRSs, extending the existing vocabularies. The vocabularies have been used to publish the French Administrative Units, with the data compatible with GeoSPARQL standards. Regarding the visualizations, after reviewing visual tools and existing applications on the Web, we have developed an ontology to better expose the data on the Web for better interoperability. We have also proposed a framework for  automatically generating visualizations based on categories detected on datasets published as Linked Data, using predefined high level categories used in Information Visualization taxonomy and mapped with vocabularies. 

Dans cette thèse, nous avons fourni des vocabulaires qui aident à la modélisation et la publication des données géospatiales intégrant la quasi-totalité des SCG, qui étendent les vocabulaires existants. Les vocabulaires ont été utilisés pour publier les unités administratives françaises, avec les données compatibles au standard GeoSPARQL. En ce qui concerne les visualisations, après avoir examiné des outils visuels et les applications existantes sur le Web, nous avons développé une ontologie pour mieux exposer les données sur le Web pour une meilleure interopérabilité. Nous avons également proposé un framework pour générer automatiquement des visualisations basées sur les catégories détectés sur des jeux de données liées et publiées, en utilisant les catégories prédéfinies de haut niveau  utilisées dans la taxonomie de la visualisation de l'information; celle-ci mappée avec les vocabulaires.





\subsection*{Review of the Contributions}
%\todo{get inspiration with Boris thesis}
This section reviews the main contributions of this thesis and the solutions to solved some of the open research problems in publishing and consuming data on the Semantic Web:

\begin{itemize}
\item We modelled and implemented of a vocabulary for geometry, topological entities and Coordinate Reference Systems (see Section \ref{sec:geomfeaturevocab}).
\item We have implemented of an API for converting data between different CRSs accessible on the Web (see Section \ref{sec:rest-service}).
\item We have published different projections systems used in France with unique URIs to improve look up and integration in structured geometries on the Web (see Section \ref{sec:reqs}).
\item We have contributed in the development of the Datalift platform, an integrated environment to publish raw data on the Web (see Section \ref{sec:toolLD}).
\item We have provided a comparison of triple stores for geodata against the geometries handled (literal or structured) to assess which one to use when publishing geospatial data (see Section \ref{sec:geotps}). 
\item We have published French administrative units available as LOD available at \url{http://data.ign.fr} endpoint, based on the vocabularies developed and implemented. Moreover, we have provided interlinking with relevant existing geospatial datasets (see Section \ref{sec:geofla} and \ref{sec:bdtopo} ).

\item We have published in RDF 15 millions of addresses from Open Street Map France using the location address vocabulary (see Section \ref{sec:bano2rdf}).
\item We have contributed to the \textit{French LOD (FrLOD)} cloud, with more datasets published using the Datalift platform, and covering the French territory (see Section \ref{sec:frenchCloud}).
\item We surveyed and classified applications built on top of Open government portals, and proposed a vocabulary for semantically annotate and improve the discovery of applications contests in Open Data event (see Section \ref{sec:descApps} and Section \ref{sec:apps}).
\item We have proposed a generic approach for automatically generating visualizations based on predefined categories (see Section \ref{sec:ldvizwiz}).
\item We have implemented and evaluated an approach for determining which properties are suitable to use for an entity, based on the Google Knowledge Panel (see Section \ref{sec:propEntities}).
\item We have developed two innovative applications consuming events and statistical datasets (see Section \ref{sec:confomaton} and Section \ref{sec:perfectSchool}).
\item We have proposed a generic plugin tool that can improve the discovery of applications contests in Open Data events (see Section \ref{sec:contests}).
\item We have also proposed an approach to harmonize prefixes used in different catalogues of vocabulary, with an evaluation based on Linked Open Vocabulary (see Section \ref{sec:prefharmoni}).
\item We have developed new ranking metrics for vocabularies based on Information Content theories and applied in LOV (see Section \ref{sec:vocabranking}).

\item Finally, we have built a more efficient tool for checking license compatibility between vocabularies and datasets (see Section \ref{sec:live}).
\end{itemize}


\section*{Perspectives}
\label{sec:future}

In this thesis, we have tackled some open research problems within the context of publishing and consuming open data on the Web but there are still open issues and challenges for future work. We  mention some of the most important from our perspective, based on different aspects related to the workflow of publishing Linked Data, more specifically in the geospatial domain. 

\subsection*{Opportunities and Challenges for IGN-France}
\label{sec:challenges}

%todo: clarify the context of the opportunities?
 The need for interoperable reference geographic data to share and combine georeferenced environmental spatial information is highlighted by the INSPIRE Directive. The INSPIRE Directive \cite{inspire2009} aims to create a European Union (EU) spatial data infrastructure\footnote{\url{ http://inspire.jrc.ec.europa.eu/index.cfm/pageid/48}}. INSPIRE is based on a number of high level common principles, with some of them very closed to the key concepts of Semantic Web goals, and specifically the Linked Data principles. We provide below the correspondence of our contributions mapped to the five goals of INSPIRE:  
\begin{itemize}
\item \textbf{P1}: \textit{Data should be collected only once and kept where it can be maintained most effectively}. The use of good and stable URI policies can help achieve this principle. IGN as a French geospatial dataset provider, is committed to accurate information, and so will be the URIs chosen for the experimental portal.
\item \textbf{P2}: \textit{It should be possible to combine seamless spatial information from different sources across Europe and share it with many users and applications}. This is more or less the goal of the interlinking tasks performed with other datasets on the wild. The models developed and well-documented can ease the conversion by other mapping agencies or institutions of their datasets.  
\item \textbf{P3}:  \textit{It should be possible for information collected at one level/scale to be shared with all levels/scales; detailed for thorough investigations, general for strategic purposes}. One of the drawback of the models proposed is that they don't currently admit many geometries attached to a feature. This will certainly be one of the extension foreseen for the models. However, the precise classifications for the features is a starter to fulfill this principle.
\item \textbf{P4}: \textit{Geographic information needed for good governance at all levels should be readily and transparently available}. Publishing \url{data.ign.fr} is one of the objective to have also data both in human and machine readable manner using semantic concepts and technologies.
\item \textbf{P5}: \textit{Easy to find what geographic information is available, how it can be used to meet a particular need, and under which conditions it can be acquired and used.} Publishing data on the web contribute \textit{per se} in leveraging their discovery and integration. Moreover, an explicit license attached to datasets published help achieving this principle.
\end{itemize}
For geographic data producers, the benefit of publishing their data on the Web according to Linked Data  (LD) principles is twofold:
\begin{enumerate}
\item First, their data are interoperable with other published datasets and they can be referenced by external resources and used as spatial reference data, which would not have been straightforward when published according to spatial data infrastructures (SDI) standards.
\item Second, the use of Semantic Web technologies can help addressing interoperability issues which are not solved yet by geographic information standards. 
\end{enumerate}
 
Moreover, the French national mapping agency (IGN) has different types of license policies for accessing data from their professional portal\footnote{\url{http://professionnels.ign.fr/}}  (e.g., research purpose, commercial use, access on demand, etc.), with some of them not necessary ``open'' or free to access: (e.g., BD TOPO\circledR). Although there is a clear understanding of the benefits of publishing and interconnecting data on the Web, ongoing investigations on how to combine licenses on datasets are under consideration at IGN. Two solutions are under investigation: 
%(i) different license policies attached to datasets and (ii) the use of a security access mechanism on top of the datasets granting access based on a predetermined configuration on named graphs and resources. 
\begin{enumerate}
\item Different license policies attached to given datasets: Here the attached license is given directly when published. So for example, if it is an open license, the endpoint is publicly available to be queried without any restriction.
\item The use of a security access mechanism on top of the datasets granting access according to a predetermined configuration list of named graphs, resources and operations allowed. This solution goes along with the work of Rotolo et al.\cite{rotolo2013deontic}, where even if there is an endpoint, a module for configuring the types of queries to perform and access policies have to be defined for subsets with special care to take into account compositions of licenses in the results.
\end{enumerate}
According to Linked Data principles URIs should remain stable, even if administrative units change or disappear. This implies adapting the data vocabulary in order to handle data versioning and time scale evolution of the data. This issue will be addressed in our future work, as we are working on releasing a spatio-temporal dataset describing the evolution of communes since the French Revolution. Another issue deals with the automation of the whole publication process, from traditional geographic data to fully interconnected RDF data.
The last issue deals with the use of multiple geometries for describing a geographic feature: geometries with different levels of detail, different CRS, different representational choices. This has been superficially addressed in our use case with the use of both polygons and points for representing respectively the surface and the centroid of departments, but should be further investigated for both query answering and map design purposes.


\subsection*{Generic Visualizations on Linked Data}
We plan to use a more exhaustive set of vocabularies in our generic queries for detecting those categories, plugging into directly the wizard to the LOV catalogue. The aggregation properties can be extended to take other semantic relations (e.g: \texttt{skos:exactMatch}) into account. Additionally, we plan to make an evaluation of the prototype and compare it to related tools such as the ones aiming to build profiles of datasets. We also need to quantify when a category is ``important'' within a dataset. For example, is it enough for a dataset to be classified GEODATA with ten triples containing location? From which number of triples could the categories and hence the visualizations be assigned? These issues can further be investigated to find the best trade-off.  Another drawback of our work on visualizations is the lack of user evaluation, with experiments to understand users' needs, focusing more on the semantic aspects than just the exploration ones (webby-interface). A natural follow-up is use these evaluations and re-adapt the applications/visualizations based on the results. 
 
\subsection*{Vocabularies and LOV}
\label{sec:nextSteps}
Work on the harmonization of prefixes can be extended in several directions. Sticking to the two services we have studied and already contributed to harmonize, the possible next steps would be to automate as far as possible the tasks that have been made semi-automatically so far:
\begin{itemize}
\item \emph{i)} developing a unique interface for submitting namespaces and prefixes to both services;
\item \emph{ii)} bridging the LOV back-office and the prefix-cc database using both services API in order to publish a list of common recommended prefixes. 
\end{itemize}  The latter goes beyond the limited framework of the two original services since such a list could be consolidated and endorsed by the main actors in vocabulary publication and management, and recommended for use in linked data applications. This could be picked up by the upcoming W3C Vocabulary Management Working Group as part of the new Data Activity\footnote{\url{http://www.w3.org/2013/05/odbp-charter.html}}.

%\todo{here is the perspective for ranking voabs} \\
\paragraph{}
 As per ranking vocabularies, we aim to take into account the equivalence axioms (between classes and properties) when computing the Information Content, and more generally, all sort of semantic relationships between terms. Also, we plan to compare our ranking model with other ranking approaches such as graph-based ones (e.g., pagerank). Another future direction is to investigate the dependency ranking between vocabularies, by focusing on a specific type of ``inlinks'' (i.e. extensions, generalizations) and study how they affect the information content (PIC) metrics.


\paragraph{}
We have made the assumption in this thesis that access to data was either by  querying a SPARQL endpoint, or by browsing or by downloading the dumps. Recently, a new way of accessing the data on the Web is emerging: through triple pattern fragments\footnote{\url{http://linkeddatafragments.org/}}. Linked Data Fragments \cite{verborgh2014ldf} aims at exploring endpoints with simple fragments to solve queries at the client side with server data.
Servers can offer data at low processing cost in a way that enables client-side querying, thus, moving intelligence from the server to the client. One possible direction of study could be to use client-side concept for evaluating endpoints consuming only structured geometries versus literal for real-world applications. Finally, triple fragment concepts can be applied also to detect also patterns for visualization in different endpoints.
 

%%%% last paragraph visionary suggested by Jodi%%
%%%%%%%%%%%%%%%%%
\paragraph{}
As the Linked Data grows, so will datasets and ontologies on geospatial data. Geodata publishers will release more often and frequently their data on the Web. There will be a need for more analytical tools, especially in data mining to provide feedback to the publishers with respect to triples usage and retrieval. Streaming geospatial data on the Web will require efficient implementations of spatial functions to be able to query on-the-fly data with temporal information. Thus, geo-temporal streaming data modeling, querying and analysis on the Web are likely to be the next challenges that Semantic Web technologies will have to solve.  
\end{document}