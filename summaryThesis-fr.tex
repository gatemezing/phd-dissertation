
\documentclass[a4paper,11pt,twoside]{report}

\usepackage[french]{babel}
\selectlanguage{french}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{fancyvrb}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs}
\bibliographystyle{unsrt}
\usepackage{url}
\usepackage{listings}
\usepackage{tabularx}
\usepackage{pdflscape}
\usepackage{subfigure}
\usepackage{wrapfig,lipsum,booktabs}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{gensymb}
\usepackage{pifont}

\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\newcommand{\trans}[1]{\noindent\textcolor{red}{{\bf \{TRANS}: #1{\bf \}}}}

\begin{document}

\chapter*{R\'{e}sum\'{e}}
Au cours de ces dernières années, le domaine de l'Open Data a reçu une attention croissante de la part des administrations publiques qui veulent tirer avantage de la publication de données ouvertes sur le Web. Les bénéfices supposés de cette ouverture pour les citoyens font référence à une meilleure transparence dans les prises de décisions publiques, à une meilleure gouvernance ou encore au développement d'un éco-système numérique qui tirerait un profit économique des applications analysant ces données. Cependant, la réalité montre que la simple ouverture et la publication de données par les administrations ne sont pas suffisantes au regard des défis liés à la variété des formats (XML, CSV, Excel, PDF, Shape), des méthodes d'accès (API, base de données) et à l'absence de nomenclature qui permettrait une meilleure réutilisation et interconnexion avec d'autres jeux de données. Dans cette thèse, nous explorons comment l'utilisation des standards et des technologies du web sémantique peut aider à résoudre les problèmes causés par l'hétérogénéité et la diversité des formats de données et des structures de représentations dans le domaine géographique.

Cette thèse applique les principes des ``données liées'' dans le domaine de l'information géographique, un domaine clef pour les administrations publiques qui couvrent, par définition, un territoire. En particulier, nous traitons de trois aspects essentiels dans le workflow de traitement et de publication de données géo-spatiales et de leur consommation (visualisation), avec des scénarios d'utilisation issus de l’Institut Nationale de l’Information Géographique et Forestière (IGN) : (1) Comment représenter efficacement et stocker des données géospatiales sur le Web pour assurer des applications interopérables ? (2) Quelles sont les meilleures options pour un utilisateur pour interagir avec des données sémantiques interconnectées ? (3) Quels mécanismes peuvent être mis en place pour aider à la préservation des données structurées de haute qualité sur le Web?

Nos contributions sont structurées en trois grandes parties correspondantes aux problématiques susmentionnées, avec des applications spécifiques dans le domaine géographique. Nous proposons et développons trois vocabulaires pour représenter des systèmes de coordonnées de référence (CRS), des entités topographiques et la géométrie associée à ces entités. Ces ontologies étendent d'autres vocabulaires existants et ajoutent deux avantages supplémentaires : l’utilisation explicite de CRS identifiés par des URIs pour représenter la géométrie, et la capacité de décrire des géométries structurées en RDF. Nous avons ainsi publié la base de données GEOFLA, en utilisant et en contribuant à la plate-forme Datalift, un outil permettant de convertir et publier des données brutes en données liées. Nous avons également évalué de manière systématique la performance des points d'accès SPARQL pour traiter des requêtes spatiales.

Concernant la ``consommation'' de données RDF, après avoir examiné les différentes catégories des outils de visualisation (génériques et spécifiques à des jeux de données), nous proposons un vocabulaire pour décrire les applications de visualisation (DVIA). En outre, nous formalisons et mettons en œuvre un workflow pour visualiser des données sémantiques interconnectées à travers l'outil LDVizWiz, un assistant de visualisation générique de données liées sur le Web.

La dernière partie de la thèse décrit des contributions au catalogue des vocabulaires liées (LOV) ainsi qu'une proposition originale pour utiliser LOV avec une méthodologie de création d'ontologie telle que NeOn dans le but d'améliorer la réutilisation des vocabulaires. Nous proposons une heuristique pour aligner les vocabulaires et un classement de ces derniers en fonction de métriques liées au contenu de l'information des termes définis dans les vocabulaires. Enfin, la thèse apporte des réponses sur la façon de vérifier la compatibilité des licences entre les vocabulaires et les jeux de données dans le workflow de publication. Tout au long de la thèse, nous démontrons les avantages de l'utilisation des technologies sémantiques et des standards du W3C pour mieux découvrir, interconnecter et visualiser les données géospatiales gouvernementales pour leur publication sur le Web.

\chapter*{Questions de recherche}
Dans cette thèse, nous proposons des solutions pour les défis liés à la publication des données géographique sur le Web des données, qui sont les suivantes :
\begin{enumerate}
\item \textit{Vocabulaires :} Comment modéliser l'information géographique sur le Web ? Comment évaluer les ontologies du domaine géographique ? Comment sérialiser les géométries complexes dans un environnement comme le Web ?
\item \textit{Languages de requêtes :} Comment écrire des requêtes efficaces qui ciblent les données géospatiales sur le Web ? Comment stocker et indexer les géodonnées représentées en RDF ?
\item \textit{Données :} Comment extraire et convertir les géodonnées pour publication sur le Web ? Quelles sont les bonnes pratiques pour représenter des géométries complexes sur le Web ? Comment intégrer pleinement la compatibilité des systèmes de coordonnées sur des jeux de données ?
\item \textit{Publication :} Comment développer des environnements qui passent à l'échelle pour couvrir le chaîne de publication des géodonnées ? Quels sont les triples stores appropriées pour le stockage des géodonnées ? Quelles sont les métriques à utiliser pour l'interconnexion de différentes ressources de géodonnées sur le Web ?
\item \textit{Applications et interfaces utilisateurs :} Comment générer des visualisations de données géospatiales liées entre elles ? Quels sont les API de haut niveau appropriées qui facilitent le développement d'interfaces utilisateur pour les données géospatiales ? Pouvons-nous réutiliser les outils de cartographie existants tels que Google Maps, Bing Maps ou OpenSteetMap ?
\end{enumerate}

Dans cette thèse, nous abordons les enjeux de publication des données tant du point de vue des éditeurs que de celui des utilisateurs. Les éditeurs et les utilisateurs ont besoin de solutions pragmatiques qui les aident à choisir un vocabulaire, trouver un outil pour convertir des fichiers Shape selon des vocabulaires existants, puis transformer en RDF et publier les données suivant des bonnes pratiques.

Après la publication du jeux de données sur le Web, les éditeurs et les utilisateurs doivent comprendre ces données pendant que les développeurs doivent pouvoir créer des applications. Le Web commence à contenir de plus en plus de données structurées, qui ne sont pas toujours exploitées par les utilisateurs finaux, à cause de la complexité du modèle RDF et de son langage de requête, SPARQL. Ainsi, il est important de créer des visualisations pour explorer, analyser et montrer les bénéfices du Linked Data aux non-experts. Dans ce processus, il existe des questions de recherches à résoudre telles que :
\begin{itemize}
 \item Comment trouver des visualisations adaptées selon les jeux de données tout en masquant la complexité du language de requêtes SPARQL ?
 \item Quelles sont les propriétés importantes pour visualiser les ressources du Web, en fonction du domaine et des attentes des utilisateurs ?
 \item Comment combler le fossé entre les outils traditionnels existants de visualisation de l'information, la plupart du temps aux formats CSV/XLS, JSON ou formats propriétaires pour intégrer facilement le modèle de données RDF en entrée ?
 \item Comment développer des applications interopérables sur les catalogues de données gouvernementaux en Open Data ? Comment réutiliser les applications existantes ?
\end{itemize}

Tout en essayant de répondre aux défis ci-dessus mentionnés, nous exposons l'état de l'art et les approches existantes dans le domaine des visualisations de données liées.

\section*{Contributions}
\label{sec:contributions}

Les contributions de cette thèse sont organisée en trois parties principales : la modélisation et la publication des données géospatiales, la visualisation de données et des applications sur le Web et la contribution dans les standards.

\subsection*{Modélisation et publication des données géospatiales}
La géolocalisation est cruciale pour de nombreuses applications tant pour agents humains que les logiciels. De plus en plus des masses de données sont ouvertes et interconnectées sur le Web. Une modélisation des données géographiques de manière efficace en réutilisant autant que possible des ontologies ou des vocabulaires existants qui décrivent à la fois les fonctionnalités géospatiales et leurs formes. Dans la première partie de notre travail, nous examinons différentes approches de modélisation utilisées dans les systèmes d'information géographique (SIG) et la communauté des données ouvertes (LOD). Notre objectif est de contribuer aux efforts réels dans la représentation des objets géographiques avec des attributs tels que l'emplacement, les points d'intérêt (POI), et les adresses sur le Web de données. Nous nous concentrons sur le territoire français et nous fournissons des exemples de vocabulaires représentatifs qui peuvent être utilisés pour décrire les objets géographiques. Nous proposons quelques alignements entre différents vocabulaires (DBpedia, schema.org, LinkedGeoData, Foursquare, etc.) afin de permettre l'interopérabilité tout en interconnectant les géodonnées en France avec d'autres jeux de données.

Concernant cet aspect de notre recherche, nos contributions sont les suivantes :
\begin{enumerate}
  \item Nous avons proposé et développé une ontologie décrivant les caractéristiques et les points d'intérêt pour le territoire français, en réutilisant une taxonomie existante (GeOnto) en l'alignant sur d'autres vocabulaires connexes dans le domaine de la géolocalisation.
  \item  Nous avons étudié comment étendre les vocabulaires existants dans le domaine géographique afin de prendre en compte une modélisation efficace des géométries complexes. Ce faisant, nous abordons les questions de représentation de géométrie complexe dans le Web de données, décrivant l'état de mise en oeuvre des fonctions géospatiales dans triples stores et une comparaison avec la nouvelle norme GeoSPARQL. Nous faisons enfin quelques recommandations et plaidons pour la réutilisation des vocabulaires plus structurées pour la publication d'entités topographiques pour mieux répondre aux exigences des données issues de IGN-France.
  \item Nous avons fait une étude comparative des triples stores, comparant leur capacité de stockage des informations spatiales et leur implémentation des fonctions topologiques ra rapport à celles déjà existantes dans les normes de l'Open Geospatial Consortium (OGC)\footnote{\url{http://www.opengeospatial.org/}}.
  \item  Nous avons conçu et développé des vocabulaires pour décrire les géométries complexes avec différents systèmes de coordonnées, avec application directe aux unités administratives françaises.
  \item Nous avons interconnecté des géodonnées du contexte français avec des jeux de données géospatiales existantes sur le Web, tels que LinkedGeodata, GADM, NUTS et Geonames.
  \item Nous avons contribué à la création du ``nuage données'' ( LOD Cloud) représentant la publication de 8 jeux de données, soit 340 millions de triplets couvrant le territoire français.
\end{enumerate}

Consommer des données sur le Web grâce à des visualisations comporte autant de défis que les applications doivent de conformer à la structure du graphe RDF, la sémantique sous-jacente du jeu de données et de l'interaction homme-machine pour comprendre facilement de quoi traitent ces données.

\subsection*{Outils de visualisation des données gouvernementales liées}
\label{visu}
Nous étudions d'abord quelques applications innovantes qui ont été développées sur des jeux de données publiées en Open Data par les gouvernements (Royaume-Uni, USA, France) et des administrations locales. Nous avons ensuite dérivé et proposé 8 cas d'utilisation (scénarios) qui peuvent être développées pour consommer des données provenant des différents fournisseurs principaux en France: INSEE, DILA, IGN, FING, etc. Nous mentionnons que les cas d'utilisation les plus intéressants sont ceux qui montrent la valeur ajoutée des jeux de données interconnectées. Ces scénarios développés et déployés, peuvent être utiles pour montrer les avantages de données liées dans une variété de domaines tels que l'éducation, le tourisme, le patrimoine culturel, les administrations civiles, les tribunaux, la médecine, etc.

En ce qui concerne les outils utilisés pour la visualisation, nous avons identifié et classer en deux catégories, en fournissant pour chacun d'eux des exemples pertinents: (i) - des outils qui fonctionnent sur des données RDF, et (ii) des outils qui fonctionnent sur d'autres formats structurés. Nous proposons donc des critères de base pour évaluer un outil de visualisation de donnée en général, avec des poids attachés à chaque critère.

Nos contributions sur la visualisation sont les suivantes :
\begin{enumerate}
 \item Nous avons construit une application des élections présidentielles du premier tour français en 2012 en utilisant les données de \url{http://data.gouv.fr} et d'autres institutions publiques. L'application disponible à \url{http://www.eurecom.fr/~atemezin/DemoElection/} a été construit avec l'outil Exhibit. Il vise à mettre en valeur l'intégration des jeux de données hétérogènes: les résultats politiques en CSV, le taux de chômage, les données des candidats, les informations des départements de France provenant des données DBpedia. L'utilisateur peut filtrer par image du candidat, le taux de chômage et par département pour voir les scores, avec des informations plus enrichies sur le département.
 \item Nous avons mis en place un outil générique pour explorer les géodonnées sur une carte, en fonction de la détection automatique des données via de requêtes SPARQL dans le nuage LOD contenant des jeux de données géospatiales.
 \item Nous avons développé une application consommatrice de données géospatiales et statistiques combinant plusieurs jeux de données dans l'éducation de provenant du portail \url{http://data.gouv.fr} .
 \item Nous avons développé une application sur les événements dans une conférence avec leurs médias supports réconciliés provenant de nombreuses plates-formes sociales (Instagram, Twitter, etc.).
 \item Nous avons implémenté un vocabulaire pour structurer les applications sur le Web de données. Le vocabulaire peut être utilisé pour découvrir des outils visuels ou graphiques utilisés pour créer des applications.
 \item Nous avons mplémenté un plugin générique pour annoter des applications déve- loppées pour des hack-athon pouvant être inclus dans une page web, permettant la génération de contenu structuré de pages Web en utilisant le vocabulaire développé.
 \item Nous avons mis en place un assistant qui analyse un jeu de données RDF et  recommande une visualisation basée sur des catégories prédéfinies, en utilisant des requêtes SPARQL génériques pour faciliter l'exploration des jeux de données publiés sur le LOD.
\end{enumerate}

\subsection*{Contributions aux standards}
\label{sec:contrib-standard}
Nous avons contribué aux activités du groupe du W3C sur les données gouvernementales liées de travail (GLD WG)\footnote{http://www.w3.org/2011/gld/} de juillet 2011 jusqu'à décembre 2013. L'objectif du Groupe de travail était de ``fournir des normes et d'autres informations qui aident les gouvernements à travers le monde dans la publication de leurs données aussi efficace qu'utilisable à l'aide des technologies du Web sémantique''.

Nous avons contribué à trois groupes de travail, et en particulier à deux documents :
\begin{enumerate}
 \item Un glossaire\footnote{\url{http://www.w3.org/TR/ld-glossary/}} pour la description des termes utilisés dans le domaine du Linked data pour les potentiels producteurs et consommateurs de données gouvernementales sur le Web
 \item Un document sur les bonnes pratiques de publication des données gouvernementales sur le Web\footnote{\url{http://www.w3.org/TR/ld-bp/}}
\end{enumerate}

En ce qui concerne l'utilisation de vocabulaires standards, nous avons contribué à :
\begin{itemize}
 \item Proposer une méthode pour harmoniser les préfixes sur le Web de données avec deux services: Linked Open vocabulaires (LOV)\footnote{\url{http://lov.okfn.org/dataset/lov/}} prefix.cc\footnote{\url{http://prefix.cc}}. le premier service est actuellement un catalogue à jour des vocabulaires utilisés sur le Web, tandis que le dernier est un service pour les développeurs pour choisir, valider et chercher des préfixes pour leurs ressources ou ontologies. L'approche proposée peut être étendue à tout le catalogue du vocabulaire tant que les vocabulaires remplissent les conditions pour être insérées dans le catalogue LOV.
 \item Concevoir et mettre en œuvre une nouvelle méthode de classement des vocabulaires sur la base des métriques du contenu de l'information et de l'information partitionnée.
 \item Nous avons développé un outil qui détermine en temps réel si les différentes licences présentes dans un jeu de données et les vocabulaires associés sont soit compatible ou non.
\end{itemize}

\chapter*{Plan de la Thèse}
\label{sec:thesis-structure}
Dans la première partie de cette thèse, nous nous concentrons sur l'étude des différents modèles et vocabulaires pour représenter la géographie et de la géométrie. Nous étudions les points d'accès aux données et décrivons les problèmes particuliers tels que les systèmes de coordonnées, et mettons en évidence nos contributions dans ce dommaine: création de nouveaux vocabulaires réutilisant les vocabulaires existants, implémentation d'un convertisseur en ligne entre des différents systèmes de coordonées, etc. Nous décrivons également comment des jeux de données géographiques peuvent ensuite être convertis en RDF en utilisant le processu d'élévation des données du projet Datalift afin de leur publication sur le Web. Nous montrons ensuite comment ces jeux de données peuvent être alignées entre elles et concluons par une analyse approfondie de ces alignements dans le cas des jeux de données de cartographie française fournis par l'Institut Géographique et Forestière (IGN -France ).

\textbf{Le Chaptitre 1} décrit les limites actuelles de représentation des géodonnées sur le Web et notre contribution sur les différents vocabulaires pour représenter les géométries, les systèmes de coordonnées de référence et les ressources topographiques. Nous proposons également des bonnes pratiques pour la publication des données géospatiales sur le Web.

\textbf{Le Chapitre 2} met l'accent sur les outils de publication et des requêtes d'interrogation des géodonnées, leurs différences et leurs applications. Nous décrivons la plate-forme Datalift, une plate-forme ouverte servant de catalyseur des sources de données brutes vers des données sémantiques et interconnectés. Après avoir comparé Datalift avec Geoknow, nous l'appliquons dans le processus de publication d'unités administratives et le Gazetteer français. Nous présentons ensuite l'état du nuage français LOD (FrLOD) des données liées et des exemples de requêtes sur des géométries structurées publiées dans le point d'accès \url{http://data.ign.fr}.

Dans la deuxième partie de la thèse, nous couvrons trois principales questions relatives à la façon de présenter les données en RDF aux utilisateurs finaux. Tout d'abord, nous présentons l'état de l'art des outils et des solutions pour la représentation visuelle et l'exploration des données en RDF (Visualbox, LODSpeaKr, Map4RDF, le modèle ``Linked Data Visualization'', etc.). Ensuite, nous présentons notre contribution: un assistant pour faciliter les visualisations automatique des points d'accès aux données sur le Web, y compris le vocabulaire spécifiant les visualisations et le prototype implémenté. Par la suite, nous présentons deux applications dans les domaines événementiel et statistique pour mettre en exergue de manière innovante la réutilisation des jeux de données liés. Enfin, nous implémentons un algorithme permettant de révéler les propriétés les plus ``importantes'' des entités des ressources pour leur visualisation en partant de la Base de Connaissance de Google (GKP) ainsi qu'une évaluation faite sur les préférences des utilisateurs.

\textbf{Le Chapitre 3} fournit une revue de littérature sur des outils de visualisation et les applications, avec leurs limites. Nous décrivons également l'état de l'art des applications sur le Web et proposons une classification des ``Applications de données liées''.

\textbf{Le Chapitre 4} présente notre contribution sur de nouvelles approches pour générer des visualisations et des applications. Nous proposons tout d'abord une nouvelle approche pour les visualisations basées sur des catégories. Nous montrons ensuite une application dans le domaine géographique. Deux applications liées aux événements et aux statistiques sont également décrits. Enfin, nous proposons la façon d'améliorer la découverte d'applications dans les événements Open Data grâce à un modèle et un plugin universel pour annoter des pages Web en RDFa.

Dans la dernière partie de la thèse dans le \textbf{Chapitre 5}, nous décrivons diverses contributions aux vocabulaires ouverts liés (description du catalogue, les publications des vocabulaires, des API et des points d'accès) : l'harmonisation des préfixes des vocabulaire, les métriques pour classer les vocabulaire  en utilisant le contenu de l'information.

Dans le \textbf{Chapitre 6}, nous présentons quelques idées sur la vérification de compatibilité des licence entre les vocabulaires et les jeux de données en utilisant la logique déontique en créant un outil en ligne pour la détection automatique des licences sur es données du Web.

Dans le \textbf{Chapitre 7}, nous concluons en mettant en évidence certaines limites et perspectives pour de nouvelles directions de recherche.

\chapter*{Partie I: Intégration des données geo-spatiales sur le Web}

\section*{Chapitre I}
Dans ce chapitre, nous faisons une revue de la litterature des formats et des différents vocabulaires utilisés pour modéliser des données géospatiales sur le Web, en distinguant deux types de géoréférencement: direct et indirect. Ensuite, nous identifions certaines limitations liés à l'absence d'une référence explicite du Systeme de coordonné géographique (SCG) dans les jeux de données actuellement publiés sur le Web. Nous proposons ensuite un service REST pour la conversion entre différents SCG pour aider les éditeurs à être capable de gérer différentes projections dans les jeux données. En outre, nous proposons et implémentons trois vocabulaires pour les géométries, les SCG et les entités topographiques qui sont en ligne aux adresses respectives à \url{http://data.ign.fr/def/geometrie}, \url{http://data.ign.fr/def/ignf} et \url{http://data.ign.fr/def/topo}. Les vocabulaires étendent ceux existants et intègrent deux avantages supplémentaires: un usage explicite de SCG identifiés par des URIs pour la géométrie et la capacité à décrire des géométries structurées en RDF. Certains de nos résultats et la description du modèle sont en cours de discussion pour la standardisation au W3C, comme par exemple étendre le standard  GeoSPARQL pour intégrer de manière plus explicite les coordonnées géographiques.

\section*{Chapitre II}
Dans ce chapitre, nous présentons une étude des outils d'extraction et de conversion de données géospatiales en RDF. Ensuite, nous décrivons \texttt{GeomRDF}, un outil développé au sein du projet Datalift qui va au-delà de l'état de l'art en fournissant des géométries structurées et conformes au standard GeoSPARQL. En outre, nous présentons les limites des modèles de données existants en suggérant des recommandations aux éditeurs de géodonnées sur les aspects de stockage de gros volumes de donnés. De même, une description détaillée de l'outil Datalift utilisé pour publier des données sur le Web est fournie, avec une attention particulière sur notre contribution à la construction du nuage des données du Linked Open Data sur des données du territoire français avec des jeux de données en 4-5 étoiles selon les principes de données liées. Enfin, nous montrons quelques cas d'utilisation du monde réel des requêtes SPARQL faisant usage tour à tour de la géométrie structurée ou des fonctions géospatiales intégrées dans le triple store. Selon les besoins des utilisateurs et les jeux de données sous-jacentes, l'utilisateur peut choisir entre la simplicité du languqge de requête SPARQL, avec des limitations au niveau du triple store (par exemple, lors de l'usage des fonctions géospatiales intégrées), ou l'expressivité du du vocabulaire que nous proposons (\texttt{geom}), comme critère dans le choix du triple store et du stockage des données géospatiales.

\chapter*{Partie II: Visualisation des graphes de données sur le Web}

\section*{Chapitre III}
Dans ce chapitre, nous décrivons les différents outils utilisés pour la visualisation des données structurées et des graphes. Nous discutons également de différents types d'applications actuellement construites basées sur des initiatives de données ouvertes du gouvernement en Open Data. Le but de cet état de l'art est de proposer de nouvelles approches de génération et des outils de visualisations et des applications sur le Web de données. Nous avons conçu et mis en œuvre un vocabulaire, \texttt{DVIA}, qui vise à modéliser des applications pour plus d'interopérabilité et de découverte d'applications et d'outil de visualisations  sur le Web.

\section*{Chapitre IV}
Dans ce chapitre, nous avons présenté une approche pour créer des visualisations au-dessus de données liées basés sur les technologies du Web sémantique. Nous avons d'abord défini sept catégories des entités qui peuvent être associés à la visualisation des jeux de données, et nous proposons de les mapper à d'autres vocabulaires de domaine. Nous présentons ensuite une description des principales composantes d'un assistant (wizard) de visualisation dans le contexte de Linked Data. Nous décrivons une implémentation en JavaScript comme \textit{preuve-de-concept} de notre proposition, avec les avantages d'être disponible en ligne et extensible. Nous pensons qu'un tel outil peut être facilement intégré dans une chaîne globale de  publication données sur le Web, tels que Datalift ou GeoKnow. En outre, nous avons effectué des expériences sur le graphe de connaissances de Google pour détecter des propriétés importantes à visualiser dans des entités, et avons évalué en fonction aux préférences des utilisateurs. Ensuite, nous avons présenté deux applications dans le domaine des statistiques et des événements, consommant différents jeux de données en RDF sur le scénario des donnés du monde réel. Nous avons discuté de la façon d'améliorer les applications développées dans des contextes de hackathon, en proposant un vocabulaire et un outil pour peupler le modèle en utilisant un plugin universel. Des exemples d'événements passés ont déjà été transformés de manière semi-automatique utilisant à la fois le vocabulaire et le plugin.

\chapter*{Partie III: Contribution au catalogue des vocabulaires liés}

\section*{Chapitre V}
Nous avons présenté dans ce chapitre notre contribution au catalogue des vocabulaires ouverts et liés, comme partie d'implémentations des avantages de l'utilisation de LOV dans la création et la gestion de l'ontologie (cas de la méthodologie de NeOn), de l'harmonisation des préfixes et l'alignement des vocabulaires publiés sur le Web, ou sur du ranking des vocabulaires en utilisant la théorie du contenu de l'information. En appliquant ce dernier aux vocabulaires, nous avons essayé d'utiliser les fonctionnalités que nous jugeons ``pertinents''  à prendre en compte lorsque l'on veut des vocabulaires (par exemple: les jeux de données réutilisés, les liens vers les vocabulaires externes). Nous comparons notre approche avec d'autres classements qui sont principalement basées sur la `` popularité '' des vocabulaires. Ce travail peut ouvrir la voie vers une évaluation des vocabulaires avec des applications dans une approche plus systémique de recommandation des classes ou propriétés dans la gestion de l'ontologie, ou dans des applications de visualisation afin de proposer la  propriété la plus appropriée à visualiser dans les ressource RDF contenant un grand nombre de propriétés.

\section*{Chapitre VI}
Dans ce chapitre, nous avons présenté un outil en ligne pour vérifier la compatibilité entre des jeux de données et des vocabulaires basés sur la logique ``RDF-defeasible'' de SPINdle. Nous avons implémenté le framework LIVE pour tester la compatibilité des licences sur les données publiés sur le Web. Le but de ce framework est de vérifier la compatibilité des licences associées aux vocabulaires utilisées pour générer un jeu de données RDF et la licence associée au jeu de données final. Plusieurs aspects d'ordre plus juridique doivent être pris en compte pour les travaux futurs. Plus précisément, nous considérons que les vocabulaires comme des données à part entière, mais ce n'est pas la seule interprétation possible. Par exemple, nous pouvons voir des vocabulaires comme une sorte de compilateur, de telle sorte qu'après la création du jeu de données, les vocabulaires externes ne sont plus utilisées. Dans ce cas, quel serait le moyen approprié pour définir un système de vérification de compatibilité ? Comme travail futur, nous étudierons en profondeur cette question ainsi que nous ferons une évaluation sur la facilité d'utilisation de l'outil en ligne LIVE pour améliorer l'interface utilisateur.

\chapter*{ Conclusion et Perspectives}
\label{ch:conc}
Cette thèse est consacrée aux défis de la publication des données géospatiales sur le Web et une approche plus générique de visualiser les données liées pour les utilisateurs. La première considère la diversité des différents formats utilisés pour publier les données géospatiales propriétaires, les différentes projections (ou systèmes de coordonnées de référence) et la représentation des géométries complexes. Cette dernière approche est différente de l'état-de-l'art dans les visualisations où la complexité du langage SPARQL et RDF est pas suffisamment cachée des utilisateurs. Une analyse approfondie de la littérature a révélé certaines limites dans la publication des données géospatiales et des outils de visualisation, à savoir :
\begin{itemize}
 \item Une présence limitée des géométries complexes représentées de manière structurée, au lieu de littéraux.
 \item L'absence d'une référence explicite aux SCG dans les données au géoréférencement direct sur le Web.
 \item L'absence d'outil de visualisation destiné aux utilisateurs permettant de comprendre facilement l'essence des données sous-jacentes publiées en LOD.
 \item Beaucoup de silos de données pour les applications publiées sur le Web, perdues dans de nombreuses pages HTML.
 \item Peu d'outils qui fournissent un environnement intégré pour la publication des données brutes en données liées, partant la modélisation de données jusqu'à l'étape finale de stockage du jeu de données dans un store RDF.
 \item La difficulté pour les éditeurs de données de comprendre et de vérifier la compatibilité des licences entre les vocabulaires et les jeux de données qu'ils réutilisent venant du LOD.
\end{itemize}

Dans cette thèse, nous avons fourni des vocabulaires qui aident à la modélisation et la publication des données géospatiales intégrant la quasi-totalité des SCG, qui étendent les vocabulaires existants. Les vocabulaires ont été utilisés pour publier les unités administratives françaises, avec les données compatibles au standard GeoSPARQL. En ce qui concerne les visualisations, après avoir examiné des outils visuels et les applications existantes sur le Web, nous avons développé une ontologie pour mieux exposer les données sur le Web pour une meilleure interopérabilité. Nous avons également proposé un framework pour générer automatiquement des visualisations basées sur les catégories détectés sur des jeux de données liées et publiées, en utilisant les catégories prédéfinies de haut niveau utilisées dans la taxonomie de la visualisation de l'information.

\subsection*{Revue des contributions}
Cette section examine les principales contributions de cette thèse et les solutions que nous avons apporté comme contributions dans le contexte de la publication des données géospatiales sur le Web. Nos contributions décrites tout au long de cette thèse sont les suivantes :

\begin{itemize}
 \item Nous avons modélisé et implémenté un vocabulaire pour la géométrie, les entités topologiques et les systèmes de coordonnées géographiques.
 \item Nous avons mis en place une API pour convertir des données en ligne entre les différents systèmes de coordonnées accessibles sur le Web.
 \item Nous avons publié les différents systèmes de projections utilisés en France avec des URI uniques pour améliorer la recherche et l'intégration des géométries structurées sur le Web.
 \item Nous avons contribué à l'élaboration de la plate-forme Datalift, un environnement intégré de publication des données brutes de formats hétérogènes sur le Web.
 \item Nous avons fourni une comparaison des triples stores pour les géodonnées en projectant les types de géométries nativement incorporées (littéral ou structurée) pour aider à la recommandation lors de la publication des données géospatiales.
 \item Nous avons publié les données sur les circonscriptions administratives françaises selon les bonnes pratiques du LOD accessible au \url{http://data.ign.fr} basées sur les vocabulaires que nous avons développé. En outre, nous avons fourni des alignements avec des jeux de données géospatiales pertinentes existantes, tel que Geonames, GADM, NUTS, INSEE, etc.
 \item Nous avons publié en RDF 15 millions d'adresses provenant d'Open Street Map France en utilisant le vocabulaire des adresses proposé par le W3C.
 \item Nous avons contribué à la création du nuage de données dans le contexte  français (FrLOD), en utilisant la plateforme Datalift, ainsi que des alignements avec des jeux de données existantes. Ces données ont la principale caractéristique de couvrir la France.
 \item Nous avons revu la littérature et avons classifié les applications construites sur des portails des données ouvertes des gouvernements, et avons proposé un vocabulaire pour annoter sémantiquement et améliorer la recherche et l'extraction d'applications crées dans le cadres des hackathon sur les données en Open Data.
 \item Nous avons proposé une approche générique pour générer automatiquement des visualisations basées sur des catégories prédéfinies à l'aide des requêtes SPARQL.
 \item Nous avons implémenté et évalué une approche pour déterminer les propriétés qui conviennent le mieux à utiliser pour choisir une entité à visualiser, basé sur une approche similaire à celle mise en oeuvre dans panel de recherche de la base de connaissance Google.
 \item Nous avons développé deux applications innovantes consommant des des données événementiels et statistiques mutualisées avec des données externes présentes dans le nuage des données liées.
 \item Nous avons proposé un plugin générique pour améliorer la découverte des applications construites dans les hackathons sur les données en Open Data
 \item Nous avons également proposé une approche pour harmoniser les préfixes utilisés dans les différents catalogues de vocabulaire, avec une évaluation faite dans le cas des vocabulaires  sur Linked Open Vocabulary (LOV).
 \item Nous avons développé de nouvelles mesures de ranking pour les vocabulaires basées sur le contenu des informations et appliqué dans LOV.
 \item Enfin, nous avons construit un outil plus efficace pour vérifier la compatibilité des licences entre les vocabulaires et les jeux de données.
\end{itemize}

\section*{Perspectives}
\label{sec:future}
Dans cette thèse, nous avons abordé certains problèmes ouverts de recherche dans le cadre de la publication et la consommation (visualisation) des données ouvertes sur le Web, mais il reste encore des questions en suspens et des défis pour des travaux futurs. Nous mentionnons quelques-uns des plus importants dans la section suivante, basés sur différents aspects liés à la chaîne d'édition des données liées, plus spécifiquement dans le domaine géospatial.

\subsection*{Opportunités et défis pour IGN-France}
\label{sec:challenges}
Le besoin de données de référence géographiques interopérables pour partager et combiner des informations environnementales spatiales géoréférencées est mis en évidence par la directive européenne INSPIRE. La directive INSPIRE vise à créer dans l'espace de l'Union Européenne (UE) une infrastructure de données spatiales\footnote{\url{http://inspire.jrc.ec.europa.eu/index.cfm/pageid/48}}. INSPIRE est basée sur un certain nombre de principes communs de haut niveau, avec certains d'entre eux très propres des principes clés appliqués dans les fondements du Web sémantique, et en particulier dans son implémentations dans les données ouvertes et liées. Nous fournissons ci-dessous la correspondance de nos contributions ayant un lien avec les cinq objectifs de la directive INSPIRE :\footnote{La traduction des objectifs est faite par nos propres soins.}
\begin{itemize}
 \item \textbf{P1}: \textit{Les données doivent être collectées une seule fois et conservées où elles peuvent être maintenues le plus efficacement possible}. L'utilisation de bonnes politiques et des URIs stables peuvent aider à atteindre ce principe. IGN comme un fournisseur de données géospatiales en France est commis à des informations exactes, ainsi que seront donc les URIs choisis et utilisés pour le portail sémantique.
 \item \textbf{P2}: \textit{Il devrait être possible de combiner des informations spatiales transparente provenant de différentes sources à travers l'Europe et les partager avec de nombreux utilisateurs et applications}. Ce principe est plus ou moins l'objectif des tâches d'interconnexion avec d'autres jeux de données dans le Web. Il faudrait restreindre les domaines de recherche dans les données européenes. Les modèles développés et bien documentés peuvent faciliter la conversion des données par d'autres organisations ou institutions utilisant ou produisant les données cartographiques.
 \item \textbf{P3}:  \textit{Il devrait être possible pour l'information recueillie à un niveau d'échelle être partagée à tous les autres niveaux ou échelles; détaillée pour des recherches approfondies et générale à des fins stratégiques}. Un des inconvénients des modèles proposés est qu'ils n'admettent pas actuellement de nombreuses géométries attachées à une entité géographique ou adresse. Ce sera certainement l'une des extensions prévue pour les vocabulaires développés. Cependant, une classification précise des entités géographiques et topologiques est un début pour remplir ce principe.
 \item \textbf{P4}: \textit{L'information géographique nécessaire pour la bonne gouvernance à tous les niveaux devrait être facilement disponible et transparente}. La publication du portail \url{http://data.ign.fr}  est l'un des objectifs afin d'avoir également des données à la fois processable par la machine et lisible par l'homme avec l'aide des concepts et des technologies sémantiques.
 \item \textbf{P5}: \textit{Accès facile pour retrouver quelle l'information géographique est disponible, comment elle peut être utilisé pour répondre à un besoin particulier, et dans quelles conditions elle peut être acquise et utilisée.} La publication des données sur le Web contribue en soit à tirer profit de leur découverte et intégration . En outre, une licence explicite attachée à aux jeux de données publiées contribue à atteindre de ce principe.
\end{itemize}

Pour les fournisseurs de données géographiques, les avantages de publier leur donnée sur le Web selon les principes du Linked Data sont de deux sortes :
\begin{enumerate}
 \item Tout d'abord, leurs données sont interopérables avec d'autres jeux de données publiées et peuvent être référencées par des ressources externes et utilisées comme des données à référence spatiale, ce qui n'auraient pas été le cas si elles étaient publiées selon les normes des infrastructures de données spatiales (SDI).
 \item Deuxièmement, l'utilisation des technologies du Web sémantique peut aider à résoudre les problèmes d'interopérabilité qui ne sont pas encore résolus par les normes et standards actuels dans le domaine de l'information géographique.
\end{enumerate}

En outre, l'agence nationale de cartographie française (IGN) dispose de différents types de politiques de licence pour accéder aux données à partir de leur portail professionnel\footnote{\url{http://professionnels.ign.fr/}} (par exemple pour des fins de recherche, l'utilisation commerciale, l'accès à la demande, etc.), avec certains accès pas nécessairement ``ouvert'' ou libre d'accès:  (par exemple, BD TOPO\circledR). Bien qu'il y ait une compréhension claire des avantages de la publication et de l'alignement des données sur le Web, les recherches à l'IGN sont en cours sur la manière de combiner les licences sur des jeux de données. Deux solutions sont à l'étude :
\begin{enumerate}
 \item Les différentes politiques de licence attachées aux jeux de données: Ici, la licence attachée est donnée directement lors de la publication. Ainsi, par exemple, s'il s'agit d'une licence libre, le point d'accès SPARQL est publiquement disponible et peut être interrogé sans aucune restriction.
 \item L'utilisation d'un mécanisme d'accès aux données donnant accès selon une liste de configuration prédéterminée de graphes dédiés, des ressources et des opérations autorisées. Cette solution va en droite ligne avec les propositions des chercheurs comme Rotolo et al. dans l'application de la logique déontique.  Cette solution suggère que même s'il y a un point d'accès, un module de configuration des types de requêtes à réaliser et des politiques d'accès doivent être définis pour les sous-ensembles de données avec un soin particulier pour tenir compte des compositions de licences dans les résultats.
\end{enumerate}

Selon les principes du Linked Data, les URIs devraient rester stables, même si les unités administratives changent ou disparaissent. Cela implique l'adaptation du vocabulaire de données afin de gérer les versions des données, l'évolution temporelle et la granularité des données. Cette question sera abordée dans nos travaux futurs, comme nous travaillons sur la publication du jeu de données spatio-temporelle décrivant l'évolution des communes depuis la Révolution française. Une autre question de recherche porte sur l'automatisation de l'ensemble du processus de publication, partant des données géographiques aux formats traditionnels (SHAPE, CSV, etc) pour arriver à des données RDF pleinement interconnectés.

La dernière question porte sur l'utilisation de plusieurs géométries pour décrire une entité géographique: des géométries avec différents niveaux de détail, avec différents CRS ainsi que des choix différents de représentation. Cela a été superficiellement abordées dans notre cas d'utilisation avec l'utilisation de deux polygones et de points pour représenter respectivement la surface et le centre de gravité des communes, mais doit être étudiée en profondeur pour proposer une solution intégrant à la fois les contraintes de requêtes et d'affichage d'informations sur des fonds de carte en fonction des besoins utilisateurs.

\subsection*{Visualisations génériques des données liées sur le Web}
Nous prévoyons d'utiliser un ensemble plus exhaustif des vocabulaires dans nos requêtes génériques pour détecter les catégories, en prenant la liste des vocabulaires du catalogue LOV pour alimenter l'assistant. Les propriétés d'agrégation peuvent être étendues afin de prendre d'autres relations sémantiques (par exemple, prendre en compte \texttt{SKOS:exactMatch}). En outre, nous prévoyons de faire une évaluation du prototype et le comparer à des outils connexes comme celles permettant de produire des statistiques des jeux de données. Nous avons également besoin de quantifier quand une catégorie est «importante» dans un jeu de données. Par exemple, est-ce suffisant pour un jeu de données pour être classé dans la catégorie ``GEODATA'' avec juste dix triplets contenant des adresses? À partir de quel nombre de triplets et donc quelle proportion pourrait-on utiliser les catégories, donc les librairies de visualisations associées? Ces questions peuvent en outre être étudiées pour trouver le meilleur compromis entre le pourcentage de représentativité de certaines catégories et les librairies correspondantes. Un  inconvénient de notre travail sur les visualisations est l'absence d'évaluation au niveau de l'utilisateur final, avec un protocole bien définit pour comprendre les besoins des utilisateurs, en se concentrant davantage sur les aspects sémantiques que sur ceux liés juste à l'exploration (interface web). Un travail futur naturel est d'utiliser ces évaluations et ré-adapter les applications/visualisations basées sur les résultats d'une étude utilisateur.

\subsection*{Vocabulaires et LOV}
\label{sec:nextSteps}
Les travaux sur l'harmonisation des préfixes peut être étendu dans plusieurs directions. En se limitant aux deux services que nous avons étudié et déjà contribué à harmoniser les prefixes, les prochaines étapes possibles seraient d'automatiser autant que possible les tâches qui ont été faites de manière semi-automatique à ce jour :
\begin{itemize}
 \item \emph{i)} le développement d'une interface unique pour soumettre les espaces de noms et les préfixes aux deux services;
 \item \emph{ii)} la couverture simulatanée des prefixes dans LOV et prefix.cc pour harmoniser les URIs des vocabulaires présents dans les deux services afin de ne confondre les utilisateurs et les développeurs dans le choix ou la gestion des espaces de noms, et ainsi proposer une liste recommandée namespaces-URIs des vocabulaires les plus importants.
\end{itemize}

Ce dernier aspect va au-delà du domaine d'application des deux services car une telle liste pourrait être consolidé et approuvé par les principaux acteurs de publication et de gestion du vocabulaire, et recommandé pour une utilisation dans les applications de données liées. Cela pourrait être pris en charge par le prochain groupe de travail du W3C\footnote{\url{http://www.w3.org/2013/05/odbp-charter.html}} chargé de gérer les vocabulaires dans le cadre de la nouvelle activité de gestion des données sur le Web.

Pour le ranking des vocabulaires, nous souhaitons dprendre en compte les axiomes d'équivalence (entre les classes et les propriétés) lors du calcul du contenu de l'information, et plus généralement, toutes sortes de relations sémantiques entre les termes. En outre, nous prévoyons de comparer notre modèle de classement avec d'autres approches telles que celles de classement fondées sur les graphes  (par exemple, le PageRank). Une autre orientation future est de chercher la dépendance dans la position entre les vocabulaires, en se concentrant sur un type spécifique de ``liens entrants'' (à savoir les extensions, les généralisations) et d'étudier comment ils affectent les métriques que nous avons présenté dans cette thèse.

Nous avons fait l'hypothèse dans cette thèse que l'accès aux données se faisait soit en interrogeant un accès SPARQL, en parcourant le graphe par le principe du ``follow-your-nose'' ou en téléchargeant des dumps. Récemment, une nouvelle façon d'accéder aux données sur le Web est en train d'émerger: à travers  des motifs de fragments triplets liés\footnote{\url{http://linkeddatafragments.org/}}. Ce concept vise à explorer les accès de données avec des fragments simples de données pour résoudre les requêtes côté client avec les données hébergées dans un serveur. Les serveurs peuvent servir des données à faible coût de traitement d'une manière qui permet l'interrogation côté client en déplaçant du même coup l'intelligence passant du serveur vers le client. Un travail futur pourrait être d'utiliser le concept côté client pour évaluer les points d'accès aux données contenant seulement les géométries structurées ou littéraux pour les applications du monde réel. Enfin, le concept de fragments de triplets  peut également être appliqué pour détecter des pattern pour la visualisation des différents point d'accès de données.

Avec la croissance continue et soutenue de la publication des données ouvertes et liées sur le Web, il en sera aussi des jeux de données et des ontologies sur des données géospatiales. Les producteurs de données  géographiques vont continuer de libérer de plus en plus fréquemment leurs données sur le Web. Cela va créer un besoin d'outils pour facilement créer des analyses, en particulier dans l'extraction et la fouille de gros volumes de données pour retro-alimenter les éditeurs quant à l'utilisation effective des triplets. La gestion des flux de données géospatiales sur le Web va demander des implémentations plus efficaces dans le domaine des données spatiales pour être en mesure d'interroger à la volée des données contenant aussi de l'information temporelle. Ainsi, la modélisation des flux de données en streaming géo-temporel, l'interrogation et l'analyse sur le Web sont susceptibles d'être les prochains défis que les technologies du Web sémantique devront faire face et résoudre.

\end{document} 